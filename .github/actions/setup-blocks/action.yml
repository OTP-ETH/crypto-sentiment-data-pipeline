name: 'Prefect Blocks'
description: 'Deploy CloudRunJob and GitHub blocks for serverless containerized execution'
branding:
  icon: cloud
  color: yellow
inputs:
  prefect_api_key:
    description: 'Prefect Cloud API key'
    required: true
  prefect_api_url:
    description: 'Prefect Cloud API URL'
    required: true
  gcp_creds_block_name:
    description: 'Name of the GCP Credentials block'
    required: false
    default: 'default'
  github_block_name:
    description: 'Name of the GitHub block'
    required: false
    default: 'default'
  cloudrun_block_name:
    description: 'Name of the CloudRunJob block'
    required: false
    default: 'default'
  gcs_block_name:
    description: 'Name of the GCS bucket block'
    required: false
    default: 'default'
  bq_block_name:
    description: 'Name of the GCS bucket block'
    required: false
    default: 'default'
  gcp_credentials_json:
    description: 'Content of the Service Account JSON key file'
    required: true
  region:
    description: GCP region
    required: true
    default: 'us-central1'
  artifact_repository:
    description: 'Artifact Registry Repository Name'
    required: false
    default: 'binance-transactions'
  image_name:
    description: 'Artifact Registry Image Name'
    required: false
    default: 'deployments'
  bucket_suffix:
    description: Postfix for GCS bucket name
    required: true
    default: 'raw-crypto-data'
  dataset_name:
    description: BigQuery dataset name
    required: true
    default: 'crypto_data'
  python_version:
    description: 'Python version'
    required: false
    default: '3.10' # the latest Prefect 2 version is used by default
  install_command:
    description: 'Can be set to e.g. pip install -r requirements.txt'
    required: false
    default: 'pip install .' # install via setup.py by default
runs:
  using: 'composite'
  steps:
    - name: Set up Python
      uses: actions/setup-python@v4

    - name: Install and configure Poetry
      uses: snok/install-poetry@v1
      with:
        virtualenvs-create: false

    - name: Install dependencies
      run: |
        poetry install --no-root
      shell: bash

    - id: login-prefect
      run: |
        poetry run prefect config set PREFECT_API_KEY=${{ inputs.prefect_api_key }}
        poetry run prefect config set PREFECT_API_URL=${{ inputs.prefect_api_url }}
      shell: bash

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v1
      with:
        credentials_json: '${{ inputs.gcp_credentials_json }}'

    - name: Set up Cloud SDK
      uses: google-github-actions/setup-gcloud@v1

    - id: set-image
      run: |
        echo "RAW_IMAGE=${{ inputs.region }}-docker.pkg.dev/$GCP_PROJECT/${{ inputs.artifact_repository }}/${{ inputs.image_name }}" >> $GITHUB_ENV
        echo "IMAGE_URI=${{ inputs.region }}-docker.pkg.dev/$GCP_PROJECT/${{ inputs.artifact_repository }}/${{ inputs.image_name }}:$GITHUB_SHA" >> $GITHUB_ENV
        echo "uri=$(echo $IMAGE_URI)" >> $GITHUB_OUTPUT
      shell: bash

    - id: create-blocks
      run: |
        cat <<EOF > blocks.py
        # Import necessary modules
        from prefect.filesystems import GitHub
        from prefect_gcp.cloud_run import CloudRunJob
        from prefect_gcp.credentials import GcpCredentials
        from prefect_gcp.cloud_storage import GcsBucket
        from prefect_gcp.bigquery import BigQueryWarehouse

        # Save GitHub storage block
        github_block = GitHub(
            repository="$GITHUB_SERVER_URL/$GITHUB_REPOSITORY",
            reference="$GITHUB_REF_NAME",
        )
        github_block.save(
            "${{ inputs.github_block_name }}",
            overwrite=True,
        )

        # Save GCP credentials block
        gcp_credentials_block = GcpCredentials(
            service_account_info=${{ inputs.gcp_credentials_json }}
        )
        gcp_credentials_block.save(
            "${{ inputs.gcp_creds_block_name }}",
            overwrite=True,
        )

        # Load GCP credentials from storage
        gcp_credentials = GcpCredentials.load("${{ inputs.gcp_creds_block_name }}")

        # Save CloudRun block to storage
        cloudrun_block = CloudRunJob(
            image="${{ env.IMAGE_URI }}",
            region="${{ inputs.region }}",
            credentials=gcp_credentials,
            cpu=2,
            timeout=3600,
        )
        cloudrun_block.save(
            "${{ inputs.cloudrun_block_name }}",
            overwrite=True,
        )

        # Save GCS bucket block to storage
        gcs_block = GcsBucket(
            bucket="$GCP_PROJECT-${{ inputs.bucket_suffix }}",
            gcp_credentials=gcp_credentials,
        )
        gcs_block.save(
            "${{ inputs.gcs_block_name }}",
            overwrite=True,
        )

        # Save BigQuery block to storage
        bq_block = BigQueryWarehouse(
            gcp_credentials=gcp_credentials,
            fetch_size=1,
        )
        bq_block.save(
            "${{ inputs.bq_block_name }}",
            overwrite=True,
        )

        EOF
        python blocks.py
      shell: bash
